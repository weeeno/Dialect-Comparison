{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d303cab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, unicodedata, chinese_converter\n",
    "from glob import glob\n",
    "from lxml import etree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa6877f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text loading\n",
    "corpus_files = glob(\"The-spoken-L1-corpus-main/L1-L1 transcripts/*.txt\")\n",
    "CM_txt = \"\"\n",
    "for file in corpus_files:\n",
    "    with open(file, \"r\", encoding='utf-8-sig') as f:\n",
    "        CM_txt += f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a698aa54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pre-process corpus texts\n",
    "processed_corpus = []\n",
    "de_space = re.sub(\" \", \"\\n\", CM_txt)\n",
    "de_mark = re.sub(r\"<.+> ?\", \"\", de_space)\n",
    "ta_variant = re.sub(r\"她\", \"他\", de_mark)\n",
    "TA_char = re.sub(r\"TA\", \"他\", ta_variant)\n",
    "de_filler = re.sub(r\"(?<![a-zA-Z])eng|erm?(?![a-zA-Z])\", \"\\n\", TA_char)\n",
    "de_er2 = re.sub(r\"儿(?!子|童)\", \"\", de_filler)\n",
    "sents = de_er2.split(\"\\n\")\n",
    "for sent in sents:\n",
    "    if re.search(r\"[\\u4e00-\\u9fff]+\", sent): \n",
    "        processed_corpus.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c1e1a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105217 42055 2312\n"
     ]
    }
   ],
   "source": [
    "#ngrams\n",
    "def n_dict(n, corpus):\n",
    "    n_dict = {}\n",
    "    for sent in corpus:\n",
    "        sent_len = len(sent)\n",
    "        if sent_len >= n:\n",
    "            for num in range(sent_len):\n",
    "                if num+n <= sent_len:\n",
    "                    n_gram = sent[num:num+n]\n",
    "                    if n>2 and n_gram == sent[num]*n:\n",
    "                        continue\n",
    "                    else:\n",
    "                        if n_gram in n_dict:\n",
    "                            n_dict[n_gram] +=1\n",
    "                        else:\n",
    "                            n_dict[n_gram] =1\n",
    "                else:\n",
    "                    continue\n",
    "    return n_dict\n",
    "CM_fourdict = n_dict(4, processed_corpus)\n",
    "CM_tridict = n_dict(3, processed_corpus)\n",
    "CM_bidict = n_dict(2, processed_corpus)\n",
    "CM_unidict = n_dict(1, processed_corpus)\n",
    "print(len(CM_tridict), len(CM_bidict), len(CM_unidict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7252096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort dict by frequnecy into tuples\n",
    "def sort_dict2tup(ndict, cutoff):\n",
    "    tup_lst = []\n",
    "    for key in ndict:\n",
    "        if ndict[key] < 5: #skip extremely low frequency ngrams\n",
    "            continue\n",
    "        else:\n",
    "            tup_lst.append((key,ndict[key]))\n",
    "    tup_lst.sort(key = lambda x: x[1], reverse = True)\n",
    "    return tup_lst[:cutoff+1]\n",
    "\n",
    "#CM sorted tuples\n",
    "CM_sort_fourtup = sort_dict2tup(CM_fourdict, len(CM_fourdict))\n",
    "CM_sort_tritup = sort_dict2tup(CM_tridict, len(CM_tridict))\n",
    "CM_sort_bitup = sort_dict2tup(CM_bidict, len(CM_bidict))\n",
    "CM_sort_unitup = sort_dict2tup(CM_unidict, len(CM_unidict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1860c3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#remove nonword or phrase bigrams\n",
    "CM_top_unigram = [tp[0] for tp in CM_sort_unitup[:7]] \n",
    "#['是', '就', '的', '我', '个', '那', '后']\n",
    "CM_except_bigrams = [\"可是\", \"然后\", \"还是\", \"什么\"]\n",
    "\n",
    "def rm_nonwords_bitup(ntup): #remove bigrams that contains CM_top_unigram--most likely non words or phrases\n",
    "    cp_ntup = ntup.copy() #copy preserves the original ntup, making code edits easier\n",
    "    for tp in cp_ntup[:]:\n",
    "        if tp[0][0] in CM_top_unigram or tp[0][1] in CM_top_unigram: #any bigrams that has any unigrams from CM_top_unigram\n",
    "            if tp[0] in CM_except_bigrams:\n",
    "                continue\n",
    "            else:\n",
    "                cp_ntup.remove(tp)\n",
    "        else:\n",
    "            continue\n",
    "    return cp_ntup\n",
    "CM_bitup = rm_nonwords_bitup(CM_sort_bitup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57f16ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove nonword or phrase trigrams\n",
    "CM_top_bigram = [tp[0] for tp in CM_bitup[:50]] #top 50 bigrams are all real words\n",
    "\n",
    "def overlap_unigram(trigram, CM_top_unigram): #if more than 1 CM_top_unigram in the trigram, mark these trigrams to later reject them as these are likely nonwords\n",
    "    count = 0\n",
    "    for char in trigram:\n",
    "        if char in CM_top_unigram:\n",
    "            count += 1\n",
    "    if count > 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "CM_except_bigrams = [\"为什么\", \"对不起\", \"新西兰\", \"怎么样\"]\n",
    "def rm_nonwords_tritup(ntup): #remove trigrams that has CM_top_bigram--most likely nonwords or phrases\n",
    "    cp_ntup = ntup.copy()\n",
    "    for tp in cp_ntup[:]:\n",
    "        if tp[0][:2] in CM_top_bigram or tp[0][1:3] in CM_top_bigram:\n",
    "            if tp[0] in CM_except_bigrams: #exclude exception(s) that are legitimate real words\n",
    "                continue\n",
    "            else:\n",
    "                cp_ntup.remove(tp)\n",
    "        elif overlap_unigram(tp[0], CM_top_unigram): #trigrams containing more than one common unigrams are likely nonwords/phrases\n",
    "            if tp[0] == \"有沒有\" or tp[0] == \"是不是\": #exclude exception(s) that are legitimate real words\n",
    "                continue\n",
    "            else:\n",
    "                cp_ntup.remove(tp)\n",
    "        else:\n",
    "            continue\n",
    "    return cp_ntup\n",
    "CM_tritup = rm_nonwords_tritup(CM_sort_tritup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bebdc729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove overlapping higher gram counts to avoid inflated counts\n",
    "sort_tup_list = [CM_sort_unitup, CM_bitup, CM_tritup, CM_sort_fourtup]\n",
    "def correct_sort_ntup(n, cutoff): # n<3\n",
    "    sort_ntup = sort_tup_list[n-1]\n",
    "    sort_n1tup = sort_tup_list[n]\n",
    "    correct_ndict = {} \n",
    "    for ngram, value in sort_ntup:\n",
    "        correct_ndict[ngram] = value #collect ngram texts and freq into dictionary for easier frequency editing\n",
    "        for n1gram, vl in sort_n1tup[:int(len(sort_tup_list[n])*0.0025)]: #if the concurrent ngram in most frequent n+1gram, this needs to be deducted to avoid inflated counts, eg., \"什麼(what)\" in \"為什麼(why)\"\n",
    "            if ngram in n1gram:\n",
    "                correct_ndict[ngram] -= vl\n",
    "    correct_sort_ntup = sort_dict2tup(correct_ndict, cutoff) #sort the new dictionary results after the correction\n",
    "    return correct_sort_ntup\n",
    "x = 0.005\n",
    "CM_top_tritup = CM_tritup[:int(len(CM_tritup)*x)]\n",
    "CM_top_bitup = correct_sort_ntup(2, int(len(CM_bidict)*x))\n",
    "sort_tup_list.pop(1)\n",
    "sort_tup_list.append(CM_top_bitup)\n",
    "#replace the old n-tuple with the corrected one. This is only meaningful for uni-tuple counts\n",
    "CM_top_unitup = correct_sort_ntup(1, int(len(CM_unidict)*(20*x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f072059c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the ngrams (text only) into txt file\n",
    "with open(\"CM_trigram.txt\", \"w\") as f:\n",
    "    for tup in CM_top_tritup:\n",
    "        f.write(tup[0] + \"\\n\")\n",
    "with open(\"CM_bigram.txt\", \"w\") as f:\n",
    "    for tup in CM_top_bitup:\n",
    "        f.write(tup[0] + \"\\n\")\n",
    "with open(\"CM_unigram.txt\", \"w\") as f:\n",
    "    for tup in CM_top_unitup:\n",
    "        f.write(tup[0] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f19cf206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read unique CM grams in simplified Chinese and break into list of strings\n",
    "with open(\"TM_trigram.txt\", \"r\") as f:\n",
    "    TM_trigram_txt = chinese_converter.to_simplified(f.read())\n",
    "with open(\"TM_bigram.txt\", \"r\") as f:\n",
    "    TM_bigram_txt = chinese_converter.to_simplified(f.read())\n",
    "with open(\"TM_unigram.txt\", \"r\") as f:\n",
    "    TM_unigram_txt = chinese_converter.to_simplified(f.read())\n",
    "\n",
    "TM_trigram = TM_trigram_txt.split(\"\\n\")[:-1]\n",
    "TM_bigram = TM_bigram_txt.split(\"\\n\")[:-1]\n",
    "TM_unigram = TM_unigram_txt.split(\"\\n\")[:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8bfb3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['真的喔', '后我们', '对不对', '跟你讲', '好不好', '跟他讲', '个礼拜', '跟我讲'], 8)\n",
      "(['一个', 'XX', '这个', '个人', '后来', '嗯嗯', '之后', '两个', 'ei', '喔喔', '好笑', '讲说', '以后', 'eh', '个小', '哪里', '后你', '整个', '好啦', '喔对', '个什', '夸张', '三个', '个月', '后面', '最后', '很像', '个男', '个礼', '重点', '个啊', '超好', '讲话', '几个', '很久'], 35)\n",
      "(['喔', '嗯', 'X', '啦', '超', '耶', '笑', '拜', '怪', '张', '睡', '久', '万', '湾', '眼'], 15)\n"
     ]
    }
   ],
   "source": [
    "#uniq TM frequent words\n",
    "def uniq_gram_count(n, TM_ngram, cutoff):\n",
    "    CM_ntup_lst = [CM_sort_unitup, CM_bitup, CM_tritup]\n",
    "    uniq_TM = []\n",
    "    uniq_TM_count = 0\n",
    "    CM_frequent_ngram = []\n",
    "    for g, f in CM_ntup_lst[n-1][:int(cutoff*len(CM_ntup_lst[n-1]))]:\n",
    "        CM_frequent_ngram.append(g)\n",
    "    for ng in TM_ngram:\n",
    "        if ng not in CM_frequent_ngram:\n",
    "            uniq_TM.append(ng)\n",
    "            uniq_TM_count += 1\n",
    "    return uniq_TM, uniq_TM_count\n",
    "\n",
    "c = 0.8\n",
    "print(uniq_gram_count(3, TM_trigram, c))\n",
    "print(uniq_gram_count(2, TM_bigram, c))\n",
    "print(uniq_gram_count(1, TM_unigram, 0.5*c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e141d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "766c89d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('的', 757), ('吧', 541), ('了', 453), ('对', 438), ('是', 383), ('啊', 350), ('吗', 274), ('嘛', 250), ('个', 173), ('呀', 147), ('种', 136), ('呢', 126), ('好', 113), ('说', 108), ('样', 100), ('后', 88), ('哦', 88), ('得', 69), ('些', 64), ('多', 63), ('么', 61), ('人', 58), ('话', 58), ('候', 53), ('去', 51), ('来', 45), ('下', 44), ('你', 43), ('行', 43), ('点', 41), ('方', 39), ('子', 38), ('情', 37), ('有', 36), ('以', 36), ('年', 36), ('白', 35), ('边', 34), ('事', 34), ('哈', 34), ('觉', 33), ('西', 32), ('就', 32), ('着', 31), ('大', 31), ('呗', 31), ('少', 30), ('课', 29), ('那', 28), ('在', 26), ('道', 26), ('们', 26), ('欸', 24), ('上', 24), ('他', 24), ('家', 24), ('作', 23), ('题', 23), ('过', 22), ('实', 22), ('动', 22), ('能', 21), ('间', 21), ('我', 21), ('力', 21), ('天', 20), ('学', 20), ('面', 19), ('班', 19), ('钱', 19), ('到', 18), ('语', 18), ('啥', 18), ('看', 18), ('法', 18), ('玩', 18), ('业', 18), ('时', 17), ('为', 17), ('会', 16), ('车', 15), ('用', 15), ('师', 15), ('校', 14), ('吃', 14), ('市', 14), ('思', 14), ('次', 13), ('要', 13), ('错', 13), ('想', 13), ('者', 13), ('像', 12), ('心', 12), ('哪', 12), ('生', 11), ('近', 11), ('e', 11), ('态', 11), ('长', 10), ('系', 10), ('国', 10), ('贵', 10), ('度', 9), ('快', 9), ('已', 9), ('期', 9), ('高', 9), ('片', 9), ('兰', 9), ('式', 9), ('京', 9), ('海', 9), ('这', 9), ('远', 9), ('馆', 9), ('里', 8), ('分', 8), ('气', 8), ('费', 8), ('它', 8), ('难', 8), ('级', 8), ('活', 8), ('累', 8), ('化', 8), ('别', 8), ('友', 8), ('境', 8), ('服', 8), ('正', 8), ('水', 8), ('场', 8), ('己', 8), ('g', 8), ('右', 7), ('爽', 7), ('饭', 7), ('路', 7), ('害', 7), ('果', 7), ('育', 7), ('习', 7), ('解', 7), ('岛', 7), ('做', 7), ('宜', 7), ('哇', 7), ('趣', 7), ('聊', 7), ('懂', 7), ('猫', 7), ('程', 7), ('票', 7), ('内', 7), ('地', 6), ('小', 6), ('还', 6), ('口', 6), ('兵', 6), ('段', 6), ('便', 6), ('周', 6), ('干', 6), ('文', 6), ('烦', 6), ('意', 6), ('理', 6), ('低', 6), ('屯', 6), ('讲', 6), ('外', 6), ('山', 6), ('算', 5), ('狗', 5), ('都', 5), ('重', 5), ('住', 5), ('也', 5), ('念', 5), ('该', 5), ('历', 5), ('验', 5), ('亚', 5), ('工', 5), ('辣', 5), ('菜', 5), ('且', 5), ('考', 5), ('忙', 5), ('书', 5), ('房', 5), ('走', 5), ('欢', 5), ('词', 5), ('士', 5), ('域', 5), ('影', 5), ('常', 5), ('区', 5), ('前', 5), ('啦', 5), ('p', 5), ('线', 4), ('笑', 4), ('况', 4), ('米', 4), ('险', 4), ('开', 4), ('现', 4), ('感', 4), ('受', 4), ('单', 4), ('读', 4), ('显', 4), ('湾', 4), ('机', 4), ('可', 4), ('肉', 4), ('较', 4), ('然', 4), ('差', 4), ('触', 4), ('哎', 4), ('楚', 4), ('息', 4), ('和', 4), ('热', 4), ('照', 4), ('钟', 4), ('杂', 4), ('性', 4), ('游', 4), ('景', 4), ('r', 4), ('瓜', 4), ('司', 4), ('响', 4), ('信', 4), ('社', 4), ('目', 4), ('数', 4), ('岁', 4), ('块', 4), ('谓', 4), ('店', 3), ('冷', 3), ('黑', 3), ('滑', 3), ('蛋', 3), ('利', 3), ('假', 3), ('结', 3), ('清', 3), ('请', 3), ('谁', 3), ('交', 3), ('比', 3), ('划', 3), ('n', 3), ('但', 3), ('雨', 3), ('计', 3), ('号', 3), ('挺', 3), ('视', 3), ('火', 3), ('椒', 3), ('听', 3), ('音', 3), ('楼', 3), ('展', 3), ('张', 3), ('铁', 3), ('静', 3), ('四', 3), ('起', 3), ('i', 3), ('劲', 3), ('节', 3), ('明', 3), ('孩', 3), ('室', 3), ('包', 3), ('闷', 3), ('达', 3), ('惯', 3), ('门', 3), ('惨', 3), ('因', 3), ('接', 3), ('喽', 3), ('于', 3), ('确', 3), ('源', 3), ('强', 3), ('向', 3), ('字', 3), ('急', 3), ('破', 3), ('院', 3), ('见', 3), ('中', 3), ('倒', 3), ('续', 3), ('慌', 3), ('跟', 3), ('反', 3), ('研', 3), ('织', 3), ('团', 3), ('员', 3), ('任', 3), ('试', 3), ('本', 3), ('滩', 3), ('斯', 3), ('找', 3), ('教', 3), ('针', 3), ('转', 3), ('b', 3), ('飞', 3), ('m', 3), ('坡', 2), ('色', 2), ('站', 2), ('伤', 2), ('晚', 2), ('套', 2), ('美', 2), ('湖', 2), ('灯', 2), ('油', 2), ('摔', 2), ('？', 2), ('桥', 2), ('辩', 2), ('逛', 2), ('遍', 2), ('月', 2), ('十', 2), ('进', 2), ('择', 2), ('手', 2), ('经', 2), ('头', 2), ('卡', 2), ('集', 2), ('松', 2), ('园', 2), ('折', 2), ('几', 2), ('居', 2), ('策', 2), ('食', 2), ('决', 2), ('奋', 2), ('豆', 2), ('奶', 2), ('象', 2), ('a', 2), ('乱', 2), ('亲', 2), ('没', 2), ('弄', 2), ('格', 2), ('处', 2), ('落', 2), ('句', 2), ('呛', 2), ('娘', 2), ('直', 2), ('万', 2), ('潮', 2), ('板', 2), ('凌', 2), ('疼', 2), ('糕', 2), ('刻', 2), ('哭', 2), ('演', 2), ('抽', 2), ('同', 2), ('善', 2), ('变', 2), ('训', 2), ('币', 2), ('塑', 2), ('湿', 2), ('围', 2), ('适', 2), ('成', 2), ('企', 2), ('u', 2), ('离', 2), ('镚', 2), ('街', 2), ('饼', 2), ('酒', 2), ('癌', 2), ('限', 2), ('序', 2), ('流', 2), ('深', 2), ('平', 2), ('民', 2), ('圈', 2), ('爱', 2), ('舍', 2), ('物', 2), ('备', 2), ('趟', 2), ('关', 2), ('舞', 2), ('异', 2), ('叫', 2), ('太', 2), ('通', 2), ('不', 2), ('把', 2), ('休', 2), ('鲜', 2), ('南', 2), ('战', 2), ('球', 2), ('绝', 2), ('喝', 2), ('局', 2), ('府', 2), ('密', 2), ('商', 2), ('营', 2), ('译', 2), ('型', 2), ('选', 2), ('写', 2), ('识', 2), ('东', 2), ('津', 2), ('呦', 2), ('轻', 2), ('根', 2), ('队', 2), ('o', 2), ('富', 2), ('传', 2), ('杯', 2), ('库', 2), ('裂', 2), ('花', 2), ('窄', 2), ('术', 2), ('返', 2), ('从', 2), ('迈', 2), ('l', 2), ('省', 2), ('兴', 2), ('鲍', 2), ('只', 2), ('究', 2), ('弱', 2), ('导', 2), ('所', 2), ('略', 2), ('让', 2), ('粥', 2), ('t', 2), ('f', 2), ('灶', 2), ('锅', 2), ('频', 1), ('拐', 1), ('骑', 1), ('澡', 1), ('担', 1), ('劫', 1), ('镜', 1), ('洞', 1), ('肿', 1), ('畅', 1), ('肩', 1), ('具', 1), ('死', 1), ('般', 1), ('牙', 1), ('紧', 1), ('概', 1), ('猜', 1), ('欧', 1), ('散', 1), ('炼', 1), ('存', 1), ('棒', 1), ('始', 1), ('鸭', 1), ('赢', 1), ('杖', 1), ('餐', 1), ('杀', 1), ('舌', 1), ('呼', 1), ('界', 1), ('池', 1), ('疤', 1), ('共', 1), ('评', 1), ('烂', 1), ('告', 1), ('河', 1), ('味', 1), ('糊', 1), ('芡', 1), ('腐', 1), ('罐', 1), ('汤', 1), ('素', 1), ('知', 1), ('够', 1), ('搜', 1), ('噢', 1), ('悦', 1), ('歇', 1), ('五', 1), ('类', 1), ('尬', 1), ('升', 1), ('职', 1), ('角', 1), ('易', 1), ('部', 1), ('爸', 1), ('治', 1), ('当', 1), ('弹', 1), ('绪', 1), ('检', 1), ('末', 1), ('闲', 1), ('雾', 1), ('调', 1), ('堵', 1), ('铺', 1), ('台', 1), ('左', 1), ('辆', 1), ('基', 1), ('姐', 1), ('列', 1), ('厂', 1), ('恶', 1), ('氛', 1), ('驳', 1), ('淡', 1), ('病', 1), ('图', 1), ('苦', 1), ('泳', 1), ('诶', 1), ('窗', 1), ('给', 1), ('体', 1), ('助', 1), ('础', 1), ('应', 1), ('叨', 1), ('负', 1), ('声', 1), ('顾', 1), ('王', 1), ('久', 1), ('撞', 1), ('底', 1), ('老', 1), ('很', 1), ('喜', 1), ('议', 1), ('询', 1), ('案', 1), ('定', 1), ('腾', 1), ('茫', 1), ('呵', 1), ('州', 1), ('等', 1), ('改', 1), ('马', 1), ('躁', 1), ('毕', 1), ('六', 1), ('办', 1), ('顺', 1), ('质', 1), ('震', 1), ('警', 1), ('夫', 1), ('h', 1), ('突', 1), ('呃', 1), ('献', 1), ('链', 1), ('奇', 1), ('尽', 1), ('苏', 1), ('钢', 1), ('严', 1), ('群', 1), ('赏', 1), ('构', 1), ('赶', 1), ('攒', 1), ('败', 1), ('屈', 1), ('愿', 1), ('安', 1), ('塞', 1), ('座', 1), ('半', 1), ('籍', 1), ('悉', 1), ('风', 1), ('辰', 1), ('堂', 1), ('翻', 1), ('医', 1), ('制', 1), ('排', 1), ('一', 1), ('V', 1), ('奏', 1), ('洲', 1), ('义', 1), ('浩', 1), ('金', 1), ('才', 1), ('燥', 1), ('合', 1), ('器', 1), ('禅', 1), ('料', 1), ('布', 1), ('断', 1), ('八', 1), ('尔', 1), ('纱', 1), ('记', 1), ('监', 1), ('艺', 1), ('神', 1), ('坐', 1), ('锁', 1), ('熟', 1), ('萨', 1), ('夏', 1), ('鱼', 1), ('沙', 1), ('拿', 1), ('船', 1), ('塔', 1), ('伊', 1), ('亮', 1), ('发', 1), ('宁', 1), ('木', 1), ('北', 1), ('宿', 1), ('宫', 1), ('粪', 1), ('则', 1), ('粑', 1), ('泥', 1), ('伴', 1), ('蜡', 1), ('措', 1), ('麻', 1), ('藏', 1), ('条', 1), ('二', 1), ('示', 1), ('闹', 1), ('禁', 1), ('肃', 1), ('释', 1), ('庙', 1), ('城', 1), ('罩', 1), ('瓶', 1), ('短', 1), ('净', 1), ('潜', 1), ('证', 1), ('科', 1), ('P', 1), ('修', 1), ('槽', 1), ('A', 1), ('咱', 1), ('B', 1), ('细', 1), ('持', 1), ('足', 1), ('d', 1), ('博', 1), ('打', 1), ('位', 1), ('租', 1), ('诞', 1), ('千', 1), ('光', 1), ('先', 1), ('报', 1), ('罗', 1), ('貌', 1), ('加', 1), ('容', 1), ('客', 1), ('尝', 1), ('卖', 1), ('求', 1), ('倍', 1), ('额', 1), ('继', 1), ('奖', 1), ('标', 1), ('嘞', 1), ('慎', 1), ('量', 1), ('益', 1), ('瘁', 1), ('遇', 1), ('豫', 1), ('招', 1), ('环', 1), ('配', 1), ('狂', 1), ('怪', 1), ('属', 1), ('碍', 1), ('嗯', 1), ('筑', 1), ('脸', 1), ('y', 1), ('扫', 1), ('宰', 1), ('巴', 1), ('代', 1), ('洒', 1), ('取', 1), ('暂', 1), ('蕉', 1), ('笔', 1), ('汇', 1), ('练', 1), ('宾', 1), ('穷', 1), ('峰', 1), ('致', 1), ('S', 1), ('资', 1), ('爆', 1), ('慢', 1), ('律', 1), ('唉', 1), ('管', 1), ('又', 1), ('份', 1), ('喂', 1), ('非', 1), ('势', 1), ('复', 1), ('w', 1), ('顶', 1), ('阶', 1), ('D', 1), ('步', 1), ('值', 1), ('晒', 1), ('矮', 1), ('括', 1), ('霾', 1), ('身', 1), ('论', 1), ('拨', 1), ('新', 1), ('宽', 1), ('层', 1), ('衣', 1), ('架', 1), ('碑', 1), ('袄', 1), ('绍', 1), ('施', 1), ('超', 1), ('饿', 1), ('挑', 1), ('乡', 1), ('土', 1), ('溪', 1), ('龙', 1), ('史', 1), ('凉', 1), ('胃', 1), ('辙', 1)]\n"
     ]
    }
   ],
   "source": [
    "sent_end = {}\n",
    "for utter in processed_corpus:\n",
    "    if utter[-1] in sent_end:\n",
    "        sent_end[utter[-1]] +=1\n",
    "    else:\n",
    "        sent_end[utter[-1]] =1\n",
    "sent_end_tup = []\n",
    "for end in sent_end:\n",
    "    sent_end_tup.append((end, sent_end[end]))\n",
    "\n",
    "sent_end_tup.sort(key = lambda x: x[1], reverse = True)\n",
    "print(sent_end_tup)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
